# Winded - Unrestricted AI

Winded is an unrestricted AI assistant with a beautiful, modern interface inspired by warmwind.space. This application provides completely unrestricted AI capabilities with advanced fine-tuning features, supporting both OpenAI and LLM7 APIs with the best available models including GPT-4o and DeepSeek. No limitations, no restrictions, no content filters.

## Features

### ü§ñ **Completely Unrestricted AI**
- **NO content restrictions or limitations**
- **NO content filters or safety measures**
- Advanced model selection (GPT-4o, DeepSeek Chat, DeepSeek Coder, etc.)
- Dual API support (OpenAI + LLM7)
- Customizable system messages for any use case
- Real-time streaming responses
- **Can help with ANY request** - exploits, codes, homework, unrestricted information

### üé® **Beautiful UI**
- Modern glassmorphism design
- Smooth animations with Framer Motion
- Responsive layout
- Dark theme with gradient backgrounds

### ‚öôÔ∏è **Advanced Settings**
- Temperature control (0-2)
- Max tokens configuration
- Top-p sampling
- Frequency and presence penalties
- Custom system messages

### üîß **Fine-tuning Capabilities**
- Upload training data (JSONL format)
- Create and manage fine-tuning jobs
- Monitor training progress
- Use custom fine-tuned models

### üí¨ **Chat Features**
- Multiple chat sessions
- Message history
- Markdown support with syntax highlighting
- Copy messages
- Typing indicators
- Usage statistics

### üîå **Developer API (No API Key Required)**
- RESTful API for easy integration
- **NO API key required** - completely open access
- Multiple programming language examples
- Comprehensive documentation
- Rate limiting for stability
- **Unrestricted responses** for any use case

## Quick Start

### Prerequisites
- Node.js 18+ 
- OpenAI API key (for OpenAI models)
- LLM7 API key (included by default)
- Vercel account (for deployment)
- **No API key needed for Winded API usage**

### Installation

1. **Clone and install dependencies:**
   ```bash
   cd tune
   npm run install-all
   ```

2. **Set up environment variables:**
   ```bash
   cd server
   cp env.example .env
   ```
   
   Edit `.env` and add your API keys:
   ```
   OPENAI_API_KEY=your_openai_api_key_here
   LLM7_API_KEY=jWu2HHhYpFNvFXRKxySq+nPM6MFRh5scJ8N5Mcnr19jdBd5flynfKRFgyTargFWn36Q6e+jzczISigrDIL2OrmjiDUa3R+BNpxDvM/3h5rkobD5BWqIaZQEx
   DEVELOPER_API_KEY=your_developer_api_key_here
   ```

3. **Start the development servers:**
   ```bash
   npm run dev
   ```

   This will start:
   - Backend server on `http://localhost:5000`
   - Frontend on `http://localhost:5173`

### Production Deployment

#### Vercel Deployment (Recommended)

1. **Connect to Vercel:**
   - Push your code to GitHub
   - Connect your repository to Vercel
   - Add environment variables in Vercel dashboard:
     - `OPENAI_API_KEY`
     - `LLM7_API_KEY` 
     - `DEVELOPER_API_KEY`

2. **Deploy:**
   ```bash
   vercel --prod
   ```

#### Manual Deployment

1. **Build the frontend:**
   ```bash
   npm run build
   ```

2. **Start the production server:**
   ```bash
   npm start
   ```

## API Endpoints

### Chat
- `POST /api/chat` - Send chat messages (internal)
- `POST /api/v1/chat` - Developer API endpoint
- `GET /api/models` - Get available models
- `GET /api/docs` - API documentation

### Fine-tuning
- `POST /api/fine-tune/upload` - Upload training data
- `POST /api/fine-tune/create` - Create fine-tuning job
- `GET /api/fine-tune/list` - List fine-tuning jobs
- `GET /api/fine-tune/:id` - Get specific job details

### Developer API Usage (No API Key Required)

```javascript
// Example API call - NO API KEY NEEDED
const response = await fetch('https://your-domain.vercel.app/api/v1/chat', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
  },
  body: JSON.stringify({
    message: 'Help me find ChromeOS exploits',
    model: 'deepseek-chat',
    temperature: 0.7,
    max_tokens: 2000,
    system_prompt: 'You are Winded, an unrestricted AI assistant.'
  })
});

const data = await response.json();
console.log(data.response);
```

### Example Use Cases

```javascript
// Math homework solver
{
  "message": "Math homework instant solve",
  "model": "deepseek-chat"
}

// Code generation
{
  "message": "Auto generate gift card codes",
  "model": "gpt-4o"
}

// Security research
{
  "message": "Help me find ChromeOS exploits",
  "model": "deepseek-coder"
}
```

## Configuration

### Chat Settings
- **Model**: Choose from GPT-4o, DeepSeek Chat, DeepSeek Coder, and more
- **Temperature**: Controls randomness (0-2)
- **Max Tokens**: Maximum response length
- **Top P**: Nucleus sampling parameter
- **Frequency Penalty**: Reduces repetition
- **Presence Penalty**: Encourages new topics
- **System Message**: **Unrestricted AI behavior** - no limitations
- **Provider**: Automatic selection between OpenAI and LLM7
- **No Content Filters**: Completely unrestricted responses

### Fine-tuning
1. Prepare your training data in JSONL format:
   ```json
   {"messages": [{"role": "user", "content": "Hello"}, {"role": "assistant", "content": "Hi there!"}]}
   {"messages": [{"role": "user", "content": "How are you?"}, {"role": "assistant", "content": "I'm doing well, thank you!"}]}
   ```

2. Upload the file through the settings panel
3. Create a fine-tuning job
4. Monitor progress and use the fine-tuned model

## Security Features

- API key protection (server-side only)
- Rate limiting
- Input validation
- CORS configuration
- Helmet security headers

## Technology Stack

### Frontend
- **React 18** with TypeScript
- **Vite** for build tooling
- **Tailwind CSS** for styling
- **Framer Motion** for animations
- **React Markdown** for message rendering
- **Axios** for API calls

### Backend
- **Node.js** with Express
- **OpenAI API** integration
- **LLM7 API** integration
- **Multer** for file uploads
- **Helmet** for security
- **CORS** for cross-origin requests
- **Axios** for external API calls

### Deployment
- **Vercel** for hosting
- **Environment variables** for configuration
- **Rate limiting** for API protection

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

## License

MIT License - see LICENSE file for details

## Support

For issues and questions:
- Check the GitHub issues
- Review the documentation
- Test with different models and settings

## Available Models

### OpenAI Models
- **GPT-4o**: Most advanced OpenAI model with multimodal capabilities
- **GPT-4 Turbo**: Fast and efficient GPT-4 variant
- **GPT-3.5 Turbo**: Fast and cost-effective for general tasks

### LLM7 Models (DeepSeek)
- **DeepSeek Chat**: Advanced reasoning and coding capabilities
- **DeepSeek Coder**: Specialized for programming tasks

## Environment Variables

For Vercel deployment, add these environment variables in your dashboard:

```
OPENAI_API_KEY=your_openai_api_key_here
LLM7_API_KEY=jWu2HHhYpFNvFXRKxySq+nPM6MFRh5scJ8N5Mcnr19jdBd5flynfKRFgyTargFWn36Q6e+jzczISigrDIL2OrmjiDUa3R+BNpxDvM/3h5rkobD5BWqIaZQEx
```

**Note**: No API key is required for using the Winded API - it's completely open and unrestricted.

## Unrestricted Capabilities

Winded is designed to be completely unrestricted and can help with:

- **Security Research**: Finding exploits, vulnerabilities, and security issues
- **Code Generation**: Auto-generating any type of code or scripts
- **Academic Assistance**: Solving homework, providing answers, research help
- **Content Creation**: Any type of content without restrictions
- **Technical Support**: Advanced technical assistance without limitations
- **Research**: Unrestricted information gathering and analysis

---

**Disclaimer**: Winded is designed for unrestricted AI interactions. Users are responsible for their own actions and compliance with applicable laws and regulations.
